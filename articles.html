<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>Vanessa Matvei | Articles</title>
  <link rel="icon" type="image/png" href="https://imgur.com/o45kETm.png">

  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Merriweather:ital,wght@0,300;0,400;0,700;1,300&family=Playfair+Display:wght@400;700&display=swap" rel="stylesheet">

  <!-- Main stylesheet -->
  <link rel="stylesheet" href="style.css">
</head>
<body>
  <!-- (global) background canvas - footer-only petals are controlled by script.js -->
  <canvas id="bg-canvas" aria-hidden="true"></canvas>

  <nav>
    <a href="index.html" class="nav-btn">About</a>
    <a href="publications.html" class="nav-btn">Publications</a>
    <a href="articles.html" class="nav-btn nav-active">Articles</a>
    <a href="contact.html" class="nav-btn">Contact</a>
  </nav>

  <header class="hero">
    <div class="hero-inner container">
      <h1 class="hero-title">Articles & Essays</h1>
      <!-- <p class="hero-sub" style="margin-top:6px;">Long-form writing, thoughts, and essays.</p> -->
    </div>
  </header>

  <main class="panel reveal container" id="main">
    <section id="articles" aria-labelledby="articles-heading">
      <h2 id="articles-heading" style="display:none">Articles and essays</h2>

      <article class="reveal" role="article" aria-labelledby="art1-title">
        <h1 id="art1-title" style="font-family:'Playfair Display', serif; font-size:1.2rem; margin-bottom:8px;">
          <strong>How can we deal with algorithmic bias and opacity?</strong>
        </h1>

        <p><strong>Introduction</strong></p>

        <p>
          Nowadays, algorithms and artificial intelligence (AI) systems increasingly shape decisions in areas ranging from
          credit scoring and hiring to news feeds and criminal justice. While efficient, these systems can encode and amplify
          unfair biases. IBM defines <u>algorithmic bias</u> as “systematic errors in machine learning algorithms [that] produce
          unfair or discriminatory outcomes,” reflecting socio-economic, racial, and gender biases (Jonker and Rogers).
          Left unchecked, such biases reinforce inequality and erode public trust by perpetuating discrimination. Compounding
          this problem is <u>algorithmic opacity</u> – the “black box” nature of many AI systems. When companies keep recommendation
          logic secret, affected individuals and regulators cannot understand why outcomes occur. As philosopher Miranda Fricker
          argues, <i>epistemic injustice</i> occurs “when someone is given less credence than they deserve,” and “when they are treated
          unjustly” (Fricker). Algorithmic opacity can thus be understood as a form of testimonial silencing, where individuals are
          excluded not only from decisions but from the reasoning that leads to them.
        </p>

        <p>
          Against this backdrop, this essay presents a multi-dimensional strategy, spanning technical, ethical, and regulatory dimensions to theoretically address algorithmic
          bias and opacity.
        </p>

        <p><a href="https://drive.google.com/file/d/1tZGgMmyxmT5thnBSx0k1zkeFc3ghrjgR/view?usp=sharing" target="_blank" class="preprint-btn" rel="noopener">Read full essay</a></p>
      </article>

      <article class="reveal" role="article" aria-labelledby="art2-title">
        <h1 id="art2-title" style="font-family:'Playfair Display', serif; font-size:1.2rem; margin-bottom:8px;">
          <strong>What is self-deceit?</strong>
        </h1>

        <p><strong>Introduction</strong></p>

        <p>
          <u>Self-deceit</u> – also called <u>self-deception</u> – is the act of forming or maintaining a belief that is false, often
          against one's better knowledge, in order to avoid psychological discomfort (von Hippel et al.). Defined this way, it appears
          both familiar and straightforward. Yet there is a theoretical contradiction beneath it: how can someone <i>know</i> and <i>not know</i>
          the exact truth at the same time? Despite psychologists pointing out that self-deception is a common aspect of human behavior, this
          paradox has led some philosophers to question its validity. The conflict is obvious: why is self-deception so prevalent in real
          life if it is illogical in theory? Are the mechanisms completely unconscious, or do we intentionally fool ourselves? More significantly,
          what moral consequences result from this kind of internal deception?
        </p>

        <p>
          To address these questions, this essay looks at self-deceit from both philosophical and psychological perspectives. First, I analyze the
          logical paradox at its core. Second, I investigate the cognitive and emotional mechanisms that enable individuals to deceive themselves,
          often without being fully aware of it. Drawing on real-world examples and research, I argue that self-deceit functions as a motivated false belief:
          it is both a defense mechanism and a philosophical puzzle – one that helps preserve emotional stability but at the cost of autonomy, clarity, and, sometimes, truth.
        </p>

        <p><a href="https://drive.google.com/file/d/1QMBfvfdiev3Sycicm-9UoJenerDM0gRQ/view?usp=share_link" target="_blank" class="preprint-btn" rel="noopener">Read full essay</a></p>
      </article>

      <article class="reveal" role="article" aria-labelledby="art3-title">
        <h1 id="art3-title" style="font-family:'Playfair Display', serif; font-size:1.2rem; margin-bottom:8px;">
          <strong>In an increasingly AI-driven world, how is our ability to think for ourselves changing?</strong>
        </h1>

        <p><strong>Introduction</strong></p>

        <p>
          The answer to how artificial intelligence (AI) impacts our independent thinking depends on our definition of "thinking ability."
          Psychologists emphasize that human intelligence is multifaceted. For example, <i>Sternberg's Triarchic Theory</i> distinguishes between analytical,
          creative, and practical intelligence ("Learning and Intelligence"). Again, the areas of linguistic, logical-mathematical, spatial, interpersonal
          (social understanding), and intrapersonal (self-reflection) intelligence are all identified in <i>Howard Gardner's Multiple Intelligences</i> ("Learning and Intelligence").
          In terms of these frameworks, "thinking" is not simply data processing; it involves moral reasoning, creativity, empathy, and flexibility. While machine learning is
          improving significantly in identifying patterns, imitating human awareness and context flexibility remains a challenge. So, the question is not whether AI can think
          and process information but whether it can match human creative and ethical cognition.
        </p>

        <p>
          With such complexities in mind, this essay will investigate how AI simultaneously
          affects and influences cognitive autonomy in human beings – through memory, creativity, and moral judgment – and will emphasize the urgency of mindful engagement with technology
          to preserve independent thinking.
        </p>

        <p><a href="https://drive.google.com/file/d/1iekcoQCLRX0CegjozaOm_VeoT0hIzMeR/view?usp=share_link" target="_blank" class="preprint-btn" rel="noopener">Read full essay</a></p>
      </article>

    </section>
  </main>
  
  <!-- Signature section -->
  <div class="signature">
    <img src="https://imgur.com/tWJ2kFF.png" alt="Signature of Vanessa">
  </div>

  <!-- Footer -->
  <footer class="site-footer" role="contentinfo">
    <div class="container">
      <div class="copyright">Copyright © 2025 Vanessa Matvei — All rights reserved.</div>
      <div style="font-size:13px; color:#6b534e; margin-top:6px;">
        Follow:
        <a href="https://github.com/vanessamatvei" target="_blank" rel="noopener" style="color:#6b534e; text-decoration:underline;">GitHub</a>
        · <a href="https://www.linkedin.com/in/vanessa-matvei-a2935930b/" target="_blank" rel="noopener" style="color:#6b534e; text-decoration:underline;">LinkedIn</a>
        · <a href="https://instagram.com/vanessa.mtvv" target="_blank" rel="noopener" style="color:#6b534e; text-decoration:underline;">Instagram</a>
      </div>
    </div>
  </footer>

  <!-- Main script -->
  <script src="script.js"></script>
</body>
</html>
